{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 07 - Neural Network LPPLS Methods\n\nTwo neural network approaches to LPPLS bubble detection from Nielsen, Sornette & Raissi (2024):\n\n1. **M-LNN** (Mono-LPPLS NN) — one network trained per series, minimizes reconstruction MSE\n2. **P-LNN** (Poly-LPPLS NN) — pre-trained on 100K synthetic series, ~700x faster than CMA-ES\n\nBoth share a physics-informed design: the network predicts nonlinear LPPLS\nparameters (tc, m, omega), then linear parameters (A, B, C1, C2) are solved\nanalytically via OLS. This makes training stable and predictions interpretable.\n\n**Reference:** Nielsen, Sornette & Raissi (2024), [arXiv:2405.12803](https://arxiv.org/abs/2405.12803)\n\n**Requirements:** `pip install fatcrash[deep]` (adds PyTorch)\n\n> **DISCLAIMER:** This software is for academic research and educational purposes only.\n> It does not constitute financial advice."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom fatcrash.data.ingest import from_sample\nfrom fatcrash.data.transforms import log_prices, time_index\nfrom fatcrash.indicators.lppls_indicator import fit_lppls\n\nplt.style.use(\"seaborn-v0_8-whitegrid\")\nplt.rcParams[\"figure.figsize\"] = (14, 6)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Load BTC data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = from_sample(\"btc\")\ndf = time_index(df)\ndf[\"log_price\"] = log_prices(df[\"close\"].values)\n\n# Focus on the 2017 bubble for demonstrations\nbubble_mask = (df.index >= \"2017-01-01\") & (df.index <= \"2018-02-06\")\nbubble_df = df[bubble_mask].copy()\n\ntimes = np.arange(len(bubble_df), dtype=np.float64)\nlp = bubble_df[\"log_price\"].values\n\nprint(f\"Bubble window: {len(bubble_df)} days ({bubble_df.index[0].date()} to {bubble_df.index[-1].date()})\")\n\nfig, ax = plt.subplots(figsize=(14, 5))\nax.plot(bubble_df.index, bubble_df[\"close\"], color=\"steelblue\")\nax.set_title(\"BTC/USD — 2017 Bubble\")\nax.set_ylabel(\"Price (USD)\")\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. M-LNN — Mono-LPPLS Neural Network\n\nOne small network (2 hidden layers, 64 units) trained **per time series**.\nThe network predicts (tc, m, omega) and the loss is the MSE between the LPPLS\nreconstruction and observed prices. No pre-training needed.\n\nArchitecture: `Linear(N, 64) → ReLU → Linear(64, 64) → ReLU → Linear(64, 3)`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from fatcrash.nn.mlnn import fit_mlnn\n\nmlnn_result = fit_mlnn(times, lp, epochs=200, lr=1e-2, seed=42)\n\nprint(\"=== M-LNN Result ===\")\nprint(f\"  tc       = {mlnn_result.tc:.1f} (day index)\")\nprint(f\"  m        = {mlnn_result.m:.4f}\")\nprint(f\"  omega    = {mlnn_result.omega:.4f}\")\nprint(f\"  B        = {mlnn_result.b:.6f}\")\nprint(f\"  RSS      = {mlnn_result.rss:.6f}\")\nprint(f\"  is_bubble = {mlnn_result.is_bubble}\")\nprint(f\"  confidence = {mlnn_result.confidence:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Classical LPPLS for comparison\n\nCMA-ES optimizer in Rust — the traditional approach."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "classical = fit_lppls(times, lp)\n\nprint(\"=== Classical LPPLS (CMA-ES) ===\")\nprint(f\"  tc       = {classical.tc:.1f}\")\nprint(f\"  m        = {classical.m:.4f}\")\nprint(f\"  omega    = {classical.omega:.4f}\")\nprint(f\"  B        = {classical.b:.6f}\")\nprint(f\"  RSS      = {classical.rss:.6f}\")\nprint(f\"  is_bubble = {classical.is_bubble}\")\n\nprint(\"\\n=== Comparison ===\")\nprint(f\"  {'Param':<10s} {'Classical':>12s} {'M-LNN':>12s}\")\nprint(f\"  {'-'*34}\")\nprint(f\"  {'tc':<10s} {classical.tc:>12.1f} {mlnn_result.tc:>12.1f}\")\nprint(f\"  {'m':<10s} {classical.m:>12.4f} {mlnn_result.m:>12.4f}\")\nprint(f\"  {'omega':<10s} {classical.omega:>12.4f} {mlnn_result.omega:>12.4f}\")\nprint(f\"  {'RSS':<10s} {classical.rss:>12.6f} {mlnn_result.rss:>12.6f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. P-LNN — Poly-LPPLS Neural Network\n\nPre-trained on synthetic LPPLS data, ~700x faster than CMA-ES at inference.\nA deeper network (4 hidden layers: 512→256→128→64) maps min-max normalized\nprices to (tc, m, omega) in a single forward pass.\n\nWe train on a small dataset here for demonstration. For production use,\ntrain on 100K+ samples."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from fatcrash.nn.plnn import train_plnn, predict_plnn\nfrom fatcrash.nn.synthetic import generate_dataset\nimport time\n\n# Train P-LNN on a small synthetic dataset (1000 samples for demo speed)\nprint(\"Training P-LNN on 1000 synthetic LPPLS series...\")\nt0 = time.time()\nplnn_model = train_plnn(\n    variant=\"P-LNN-demo\",\n    n_samples=1000,\n    n_obs=252,\n    batch_size=8,\n    epochs=5,\n    lr=1e-4,\n    seed=42,\n)\ntrain_time = time.time() - t0\nprint(f\"Training took {train_time:.1f}s\")\n\n# Inference on real data\nt0 = time.time()\nplnn_result = predict_plnn(plnn_model, times, lp, window_size=252)\ninfer_time = time.time() - t0\n\nprint(f\"\\n=== P-LNN Result (inference: {infer_time*1000:.1f}ms) ===\")\nprint(f\"  tc       = {plnn_result.tc:.1f}\")\nprint(f\"  m        = {plnn_result.m:.4f}\")\nprint(f\"  omega    = {plnn_result.omega:.4f}\")\nprint(f\"  B        = {plnn_result.b:.6f}\")\nprint(f\"  RSS      = {plnn_result.rss:.6f}\")\nprint(f\"  is_bubble = {plnn_result.is_bubble}\")\nprint(f\"  confidence = {plnn_result.confidence:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Synthetic data visualization\n\nThe P-LNN is trained on synthetic LPPLS series with controlled noise.\nLet's visualize what the training data looks like."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from fatcrash.nn.synthetic import generate_lppls_series, add_white_noise, add_ar1_noise\n\nrng = np.random.default_rng(42)\nfig, axes = plt.subplots(2, 3, figsize=(16, 8))\n\nfor i in range(3):\n    clean, params = generate_lppls_series(n_obs=252, rng=rng)\n    noisy_white = add_white_noise(clean, alpha=0.05, rng=rng)\n    noisy_ar1 = add_ar1_noise(clean, phi=0.9, amplitude=0.03, rng=rng)\n\n    axes[0, i].plot(clean, \"k-\", linewidth=0.8, label=\"Clean\")\n    axes[0, i].plot(noisy_white, \"b-\", alpha=0.5, linewidth=0.5, label=\"+ White noise\")\n    axes[0, i].set_title(f\"tc={params['tc']:.0f}, m={params['m']:.2f}, ω={params['omega']:.1f}\")\n    if i == 0:\n        axes[0, i].legend(fontsize=8)\n        axes[0, i].set_ylabel(\"White noise\")\n\n    axes[1, i].plot(clean, \"k-\", linewidth=0.8, label=\"Clean\")\n    axes[1, i].plot(noisy_ar1, \"r-\", alpha=0.5, linewidth=0.5, label=\"+ AR(1) noise\")\n    if i == 0:\n        axes[1, i].legend(fontsize=8)\n        axes[1, i].set_ylabel(\"AR(1) noise\")\n\nfig.suptitle(\"Synthetic LPPLS Training Data\", fontsize=13)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from fatcrash.aggregator.signals import (\n    mlnn_signal, plnn_signal, aggregate_signals,\n)\n\n# Convert NN results to [0, 1] signals\ns_mlnn = mlnn_signal(mlnn_result.confidence, mlnn_result.is_bubble)\ns_plnn = plnn_signal(plnn_result.confidence, plnn_result.is_bubble)\n\nprint(\"=== NN Signal Values ===\")\nprint(f\"  M-LNN signal  = {s_mlnn:.4f} (is_bubble={mlnn_result.is_bubble})\")\nprint(f\"  P-LNN signal  = {s_plnn:.4f} (is_bubble={plnn_result.is_bubble})\")\n\n# Example aggregation with just the NN signals\ncomponents = {\n    \"mlnn_signal\": s_mlnn,\n    \"plnn_signal\": s_plnn,\n}\ncrash = aggregate_signals(components)\nprint(f\"\\n=== Aggregated (NN only) ===\")\nprint(f\"  probability = {crash.probability:.4f}\")\nprint(f\"  level       = {crash.level}\")\nprint(f\"  n_agreeing  = {crash.n_agreeing} categories\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import tempfile, os\nfrom fatcrash.nn.plnn import load_plnn\n\nwith tempfile.TemporaryDirectory() as tmpdir:\n    # P-LNN save/load\n    plnn_path = os.path.join(tmpdir, \"plnn_demo.pt\")\n    plnn_model.save(plnn_path)\n    plnn_loaded = load_plnn(plnn_path)\n    r = predict_plnn(plnn_loaded, times, lp, window_size=252)\n    print(f\"P-LNN save/load roundtrip OK — tc={r.tc:.1f}, m={r.m:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}