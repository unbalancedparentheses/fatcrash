{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 10 - DTCAI: Distance-to-Crash AI\n",
    "\n",
    "DTCAI (Lee, Jeong, Park & Ahn, 2025) addresses a fundamental weakness of LPPLS:\n",
    "**most LPPLS fits are unreliable**. The method trains a classifier on the 7\n",
    "LPPLS parameters to predict whether a fit is \"reliable\" (predicted tc within\n",
    "10 days of an actual crash). The final score is:\n",
    "\n",
    "$$\\text{DTCAI} = \\text{DTC} \\times P(\\text{reliable})$$\n",
    "\n",
    "where DTC (Distance-to-Crash) = $(t_2 - t_1) / (t_c - t_1)$ measures how\n",
    "close the current time is to the predicted critical time.\n",
    "\n",
    "This notebook:\n",
    "1. Generates a labeled dataset from BTC price history\n",
    "2. Trains three classifier variants (ANN, Random Forest, Logistic Regression)\n",
    "3. Evaluates classifier accuracy and compares model types\n",
    "4. Runs DTCAI predictions on historical episodes\n",
    "5. Compares DTCAI vs. raw LPPLS confidence\n",
    "\n",
    "> **Reference:** Lee, G., Jeong, M., Park, T. & Ahn, K. (2025).\n",
    "> \"More Than Ex-Post Fitting: LPPL and Its AI-Based Classification.\"\n",
    "> *Humanities and Social Sciences Communications*, 12, 236.\n",
    "\n",
    "> **DISCLAIMER:** This software is for academic research and educational purposes only.\n",
    "> It does not constitute financial advice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fatcrash.data.ingest import from_sample\n",
    "from fatcrash.data.transforms import log_prices, time_index\n",
    "from fatcrash.nn.dtcai_data import (\n",
    "    generate_dtcai_dataset,\n",
    "    FEATURE_NAMES,\n",
    ")\n",
    "from fatcrash.nn.dtcai import (\n",
    "    train_dtcai,\n",
    "    predict_dtcai,\n",
    "    compute_dtc,\n",
    ")\n",
    "from fatcrash.nn.crash_labels import detect_crashes\n",
    "from fatcrash.indicators.lppls_indicator import compute_confidence\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. The DTCAI pipeline\n",
    "\n",
    "The key insight: raw LPPLS fits produce many false positives. Instead of\n",
    "trusting every fit, we ask: \"does this set of fitted parameters *look like*\n",
    "parameters that historically preceded actual crashes?\"\n",
    "\n",
    "```\n",
    "Price series\n",
    "  --> Rolling LPPLS fits (multiple seeds per window)\n",
    "    --> Extract 7 parameters: (A, B, C, tc, phi, omega, beta)\n",
    "      --> Label each fit: reliable (tc near actual crash) vs unreliable\n",
    "        --> Train classifier on (params -> reliable?)\n",
    "          --> At prediction time: DTCAI = DTC * P(reliable)\n",
    "```\n",
    "\n",
    "The 7 features are:\n",
    "- **A, B**: Linear LPPLS parameters (level and trend)\n",
    "- **C**: Oscillation amplitude = sqrt(C1^2 + C2^2)\n",
    "- **tc**: Predicted critical time\n",
    "- **phi**: Oscillation phase = atan2(C2, C1)\n",
    "- **omega**: Log-periodic frequency\n",
    "- **beta**: Power-law exponent (= m in standard LPPLS notation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Generate labeled dataset\n",
    "\n",
    "We run LPPLS fits across rolling windows on BTC history, then label each\n",
    "fit using the Bree & Joseph (2013) crash criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc = from_sample(\"btc\")\n",
    "prices = df_btc[\"close\"].values\n",
    "\n",
    "print(f\"BTC: {len(prices)} daily observations\")\n",
    "print(f\"Date range: {df_btc.index[0].date()} to {df_btc.index[-1].date()}\")\n",
    "\n",
    "# Detect actual crashes using Bree & Joseph criterion\n",
    "crashes = detect_crashes(prices, lookback=262, forward=60, threshold=0.25)\n",
    "print(f\"\\nDetected {len(crashes)} crash events:\")\n",
    "for c in crashes:\n",
    "    peak_date = df_btc.index[c.peak_date_idx].date()\n",
    "    trough_date = df_btc.index[c.trough_date_idx].date()\n",
    "    print(f\"  Peak {peak_date}, trough {trough_date}, drawdown {c.drawdown:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate labeled LPPLS parameter dataset\n",
    "# This runs many LPPLS fits -- takes a few minutes\n",
    "print(\"Generating DTCAI dataset (rolling LPPLS fits)...\")\n",
    "dataset = generate_dtcai_dataset(\n",
    "    prices,\n",
    "    window_size=504,   # ~2 years\n",
    "    step_size=21,      # ~1 month between windows\n",
    "    n_fits_per_window=5,  # 5 fits per window (faster for demo)\n",
    "    crash_lookback=262,\n",
    "    crash_forward=60,\n",
    "    crash_threshold=0.25,\n",
    "    tc_tolerance=10,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset: {len(dataset.X)} labeled LPPLS fits\")\n",
    "print(f\"  Reliable (label=1): {dataset.y.sum()}\")\n",
    "print(f\"  Unreliable (label=0): {(dataset.y == 0).sum()}\")\n",
    "print(f\"  Reliable fraction: {dataset.y.mean():.1%}\")\n",
    "print(f\"  Features: {dataset.feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Explore the feature space\n",
    "\n",
    "Visualize how reliable vs. unreliable fits differ in parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dataset.X) > 0:\n",
    "    df_feat = pd.DataFrame(dataset.X, columns=FEATURE_NAMES)\n",
    "    df_feat[\"reliable\"] = dataset.y\n",
    "\n",
    "    # Summary statistics by label\n",
    "    print(\"Feature statistics by label:\")\n",
    "    print()\n",
    "    display(df_feat.groupby(\"reliable\")[FEATURE_NAMES].mean().T.round(3))\n",
    "else:\n",
    "    print(\"No data generated -- check dataset generation above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dataset.X) > 0:\n",
    "    # Pairwise scatter: omega vs beta colored by label\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "    pairs = [(\"omega\", \"beta\"), (\"tc\", \"C\"), (\"A\", \"B\")]\n",
    "    for ax, (fx, fy) in zip(axes, pairs):\n",
    "        mask_0 = dataset.y == 0\n",
    "        mask_1 = dataset.y == 1\n",
    "        ax.scatter(df_feat.loc[mask_0, fx], df_feat.loc[mask_0, fy],\n",
    "                   c=\"gray\", alpha=0.3, s=10, label=\"Unreliable\")\n",
    "        ax.scatter(df_feat.loc[mask_1, fx], df_feat.loc[mask_1, fy],\n",
    "                   c=\"red\", alpha=0.6, s=20, label=\"Reliable\")\n",
    "        ax.set_xlabel(fx)\n",
    "        ax.set_ylabel(fy)\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    fig.suptitle(\"LPPLS Parameter Space: Reliable vs Unreliable Fits\", fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Train classifiers\n",
    "\n",
    "We train three model types from the paper:\n",
    "- **ANN**: 4-layer neural network (Input(7) -> 256 -> 128 -> 64 -> 1)\n",
    "- **RF**: Random Forest (100 trees)\n",
    "- **LogReg**: Logistic Regression baseline\n",
    "\n",
    "All use random oversampling to handle class imbalance (most fits are unreliable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for model_type in [\"RF\", \"LogReg\"]:\n",
    "    print(f\"\\nTraining {model_type}...\")\n",
    "    try:\n",
    "        m = train_dtcai(dataset, model_type=model_type, seed=42)\n",
    "        models[model_type] = m\n",
    "        print(f\"  {model_type} trained successfully.\")\n",
    "    except ImportError as e:\n",
    "        print(f\"  Skipped: {e}\")\n",
    "\n",
    "# Try ANN (requires PyTorch)\n",
    "print(\"\\nTraining ANN...\")\n",
    "try:\n",
    "    m = train_dtcai(dataset, model_type=\"ANN\", epochs=50, lr=0.01, seed=42)\n",
    "    models[\"ANN\"] = m\n",
    "    print(\"  ANN trained successfully.\")\n",
    "except ImportError as e:\n",
    "    print(f\"  Skipped (PyTorch not installed): {e}\")\n",
    "\n",
    "print(f\"\\nTrained models: {list(models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Evaluate classifiers\n",
    "\n",
    "Quick evaluation: run predictions on the training data and compute accuracy.\n",
    "(For a proper evaluation, use the accuracy report which does train/test splits.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fatcrash.nn.dtcai import _predict_reliability\n",
    "\n",
    "eval_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    preds = []\n",
    "    for i in range(len(dataset.X)):\n",
    "        prob = _predict_reliability(model, dataset.X[i])\n",
    "        preds.append(prob)\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    # Binary predictions at 0.5 threshold\n",
    "    y_pred = (preds >= 0.5).astype(int)\n",
    "    y_true = dataset.y\n",
    "\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    # Precision/recall for the reliable class\n",
    "    tp = ((y_pred == 1) & (y_true == 1)).sum()\n",
    "    fp = ((y_pred == 1) & (y_true == 0)).sum()\n",
    "    fn = ((y_pred == 0) & (y_true == 1)).sum()\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "\n",
    "    eval_results.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "    })\n",
    "    print(f\"{name:>8s}: acc={acc:.3f}, prec={prec:.3f}, rec={rec:.3f}, F1={f1:.3f}\")\n",
    "\n",
    "eval_df = pd.DataFrame(eval_results)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(eval_df) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    x = np.arange(len(eval_df))\n",
    "    width = 0.2\n",
    "\n",
    "    for i, metric in enumerate([\"precision\", \"recall\", \"f1\"]):\n",
    "        ax.bar(x + i * width, eval_df[metric], width, label=metric.title())\n",
    "\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(eval_df[\"model\"])\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(\"DTCAI Classifier Comparison\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 6. Run DTCAI predictions on historical windows\n",
    "\n",
    "Use the best model to compute DTCAI scores across rolling windows\n",
    "of BTC history. Compare with raw LPPLS confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the best available model\n",
    "best_name = eval_df.loc[eval_df[\"f1\"].idxmax(), \"model\"] if len(eval_df) > 0 else None\n",
    "print(f\"Using model: {best_name}\")\n",
    "\n",
    "if best_name:\n",
    "    best_model = models[best_name]\n",
    "\n",
    "    # Compute LPPLS confidence for comparison\n",
    "    lp = log_prices(df_btc)\n",
    "    t = time_index(df_btc)\n",
    "    conf_arr, tc_mean_arr, tc_std_arr = compute_confidence(\n",
    "        t, lp, n_windows=30, n_candidates=20,\n",
    "    )\n",
    "\n",
    "    # Compute rolling DTCAI scores\n",
    "    window_size = 504\n",
    "    step = 21\n",
    "    log_p = np.log(np.maximum(prices, 1e-10))\n",
    "\n",
    "    dtcai_dates = []\n",
    "    dtcai_scores = []\n",
    "    dtc_scores = []\n",
    "    reliability_scores = []\n",
    "\n",
    "    for start in range(0, len(prices) - window_size, step):\n",
    "        end = start + window_size\n",
    "        window_t = np.arange(start, end, dtype=np.float64)\n",
    "        window_lp = log_p[start:end]\n",
    "\n",
    "        try:\n",
    "            result = predict_dtcai(best_model, window_t, window_lp)\n",
    "            dtcai_dates.append(df_btc.index[end - 1])\n",
    "            dtcai_scores.append(result.dtcai)\n",
    "            dtc_scores.append(result.dtc)\n",
    "            reliability_scores.append(result.reliability)\n",
    "        except Exception:\n",
    "            dtcai_dates.append(df_btc.index[end - 1])\n",
    "            dtcai_scores.append(np.nan)\n",
    "            dtc_scores.append(np.nan)\n",
    "            reliability_scores.append(np.nan)\n",
    "\n",
    "    dtcai_dates = pd.DatetimeIndex(dtcai_dates)\n",
    "    dtcai_scores = np.array(dtcai_scores)\n",
    "    dtc_scores = np.array(dtc_scores)\n",
    "    reliability_scores = np.array(reliability_scores)\n",
    "\n",
    "    print(f\"Computed {len(dtcai_scores)} DTCAI scores\")\n",
    "    valid = dtcai_scores[~np.isnan(dtcai_scores)]\n",
    "    print(f\"  Valid: {len(valid)}, mean={valid.mean():.3f}, max={valid.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_name:\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 14), sharex=True)\n",
    "\n",
    "    # Price\n",
    "    axes[0].plot(df_btc.index, df_btc[\"close\"], color=\"steelblue\", linewidth=0.8)\n",
    "    axes[0].set_yscale(\"log\")\n",
    "    axes[0].set_ylabel(\"Price (USD)\")\n",
    "    axes[0].set_title(\"BTC/USD Price\")\n",
    "\n",
    "    # Mark crash peaks\n",
    "    for c in crashes:\n",
    "        axes[0].axvline(df_btc.index[c.peak_date_idx], color=\"red\",\n",
    "                        linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # LPPLS confidence\n",
    "    axes[1].plot(df_btc.index[:len(conf_arr)], conf_arr,\n",
    "                 color=\"blue\", linewidth=0.8, alpha=0.7)\n",
    "    axes[1].set_ylabel(\"LPPLS Confidence\")\n",
    "    axes[1].set_title(\"Raw LPPLS Confidence\")\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    for c in crashes:\n",
    "        axes[1].axvline(df_btc.index[c.peak_date_idx], color=\"red\",\n",
    "                        linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # DTCAI score\n",
    "    axes[2].plot(dtcai_dates, dtcai_scores, color=\"darkred\",\n",
    "                 linewidth=1.0, alpha=0.8)\n",
    "    axes[2].fill_between(dtcai_dates, 0, dtcai_scores,\n",
    "                         where=np.array(dtcai_scores) > 0.5,\n",
    "                         color=\"red\", alpha=0.3)\n",
    "    axes[2].set_ylabel(\"DTCAI Score\")\n",
    "    axes[2].set_title(f\"DTCAI ({best_name}) = DTC * P(reliable)\")\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    for c in crashes:\n",
    "        axes[2].axvline(df_btc.index[c.peak_date_idx], color=\"red\",\n",
    "                        linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # Reliability vs DTC breakdown\n",
    "    axes[3].plot(dtcai_dates, reliability_scores, color=\"green\",\n",
    "                 linewidth=0.8, alpha=0.7, label=\"P(reliable)\")\n",
    "    axes[3].plot(dtcai_dates, dtc_scores, color=\"orange\",\n",
    "                 linewidth=0.8, alpha=0.7, label=\"DTC\")\n",
    "    axes[3].set_ylabel(\"Score\")\n",
    "    axes[3].set_title(\"DTCAI Components\")\n",
    "    axes[3].set_ylim(0, 1)\n",
    "    axes[3].legend()\n",
    "    for c in crashes:\n",
    "        axes[3].axvline(df_btc.index[c.peak_date_idx], color=\"red\",\n",
    "                        linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 7. DTCAI vs LPPLS comparison table\n",
    "\n",
    "For each known crash, compare the DTCAI score and raw LPPLS confidence\n",
    "in the 60 days before the peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_name:\n",
    "    comparison = []\n",
    "    for c in crashes:\n",
    "        peak_date = df_btc.index[c.peak_date_idx]\n",
    "\n",
    "        # LPPLS confidence 60d before peak\n",
    "        lppls_mask = (\n",
    "            (df_btc.index >= peak_date - pd.Timedelta(days=60))\n",
    "            & (df_btc.index <= peak_date)\n",
    "        )\n",
    "        lppls_idx = np.where(lppls_mask)[0]\n",
    "        lppls_vals = conf_arr[lppls_idx[lppls_idx < len(conf_arr)]]\n",
    "        lppls_vals = lppls_vals[~np.isnan(lppls_vals)]\n",
    "\n",
    "        # DTCAI 60d before peak\n",
    "        dtcai_mask = (\n",
    "            (dtcai_dates >= peak_date - pd.Timedelta(days=60))\n",
    "            & (dtcai_dates <= peak_date)\n",
    "        )\n",
    "        dtcai_vals = dtcai_scores[dtcai_mask]\n",
    "        dtcai_vals = dtcai_vals[~np.isnan(dtcai_vals)]\n",
    "\n",
    "        comparison.append({\n",
    "            \"crash\": f\"{peak_date.date()} ({c.drawdown:.0%})\",\n",
    "            \"lppls_max\": lppls_vals.max() if len(lppls_vals) > 0 else np.nan,\n",
    "            \"lppls_mean\": lppls_vals.mean() if len(lppls_vals) > 0 else np.nan,\n",
    "            \"dtcai_max\": dtcai_vals.max() if len(dtcai_vals) > 0 else np.nan,\n",
    "            \"dtcai_mean\": dtcai_vals.mean() if len(dtcai_vals) > 0 else np.nan,\n",
    "        })\n",
    "\n",
    "    comp_df = pd.DataFrame(comparison)\n",
    "    print(\"60-day pre-crash signal comparison:\")\n",
    "    display(comp_df.style.format({\n",
    "        \"lppls_max\": \"{:.3f}\", \"lppls_mean\": \"{:.3f}\",\n",
    "        \"dtcai_max\": \"{:.3f}\", \"dtcai_mean\": \"{:.3f}\",\n",
    "    }))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 8. Feature importance (Random Forest)\n",
    "\n",
    "If a Random Forest was trained, examine which LPPLS parameters\n",
    "are most predictive of reliable fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"RF\" in models:\n",
    "    rf = models[\"RF\"]\n",
    "    importances = rf.model.feature_importances_\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    idx = np.argsort(importances)[::-1]\n",
    "    ax.bar(range(7), importances[idx], color=\"steelblue\")\n",
    "    ax.set_xticks(range(7))\n",
    "    ax.set_xticklabels([FEATURE_NAMES[i] for i in idx])\n",
    "    ax.set_ylabel(\"Feature Importance\")\n",
    "    ax.set_title(\"Random Forest: Which LPPLS Parameters Predict Reliability?\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    for i in idx:\n",
    "        print(f\"  {FEATURE_NAMES[i]:>8s}: {importances[i]:.3f}\")\n",
    "else:\n",
    "    print(\"RF model not available. Install scikit-learn: pip install fatcrash[deep]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key findings\n",
    "- **Most LPPLS fits are unreliable** â€” the classifier learns to separate the\n",
    "  signal from noise in the 7-dimensional parameter space.\n",
    "- **DTCAI filters false positives**: by weighting the DTC ratio by P(reliable),\n",
    "  the score is high only when both the timing is close *and* the parameters\n",
    "  look historically credible.\n",
    "- Random Forest often outperforms LogReg and is competitive with ANN,\n",
    "  with the advantage of interpretable feature importances.\n",
    "- The **tc** and **omega** parameters tend to be the most discriminative\n",
    "  features for separating reliable from unreliable fits.\n",
    "\n",
    "### Limitations\n",
    "- Training and prediction are done on the same asset (BTC). Cross-asset\n",
    "  generalization remains an open question.\n",
    "- The label definition (tc within 10 days of actual crash) is sensitive\n",
    "  to the crash detection criterion.\n",
    "- Class imbalance (few reliable fits) limits precision.\n",
    "\n",
    "### Connection to the aggregator\n",
    "The DTCAI score feeds into the aggregator as `dtcai_signal` with weight 0.06\n",
    "(see `fatcrash.aggregator.signals.DEFAULT_WEIGHTS`). It provides an\n",
    "independent AI-based assessment complementing the traditional LPPLS\n",
    "confidence indicator.\n",
    "\n",
    "*All numbers are in-sample on historical data. This is not financial advice.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}